{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHQlcZT2i0ys"
   },
   "source": [
    "# Comparative Study of Neural Network, and CNN using the CIFAR-10 Dataset in Keras.\n",
    "\n",
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "In this homework, you will learn about the experiences of training Neural Networks using the Keras framework. Keras is a deep learning API written in Python, capable of running on top of JAX, TensorFlow, or PyTorch. It's very simple and straightforward. For further information, you can refer to the [official documentation](https://keras.io/). Additionally, here are four basic tutorial resources for learning how to use Keras.\n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/mnist-dataset-prediction-using-keras/\n",
    "- https://github.com/wxs/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb\n",
    "- https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
    "- https://keras.io/examples/vision/mnist_convnet/\n",
    "\n",
    "\n",
    "## Instruction \n",
    "\n",
    "- Submit your assignments onto **Canvas** by the due date.\n",
    "- This is an **individual** assignment. All help from others (from the web, books other than text, or people other than the TA or instructor) must be clearly acknowledged. \n",
    "- Most coding parts can be finished with about 1-6 lines of codes. \n",
    "\n",
    "\n",
    "\n",
    "## Rubric\n",
    "\n",
    "The assignment is worth 65 points in total:\n",
    "\n",
    "### Part 1: Neural Network ( 50 points)\n",
    "\n",
    "- Step 1: Design, compile, train, and evaluate a simple neural network (10 points)\n",
    "\n",
    "- Step 2: Experiment with different activation functions and evaluate their influence on model performance (10 points)\n",
    "\n",
    "- Step 3: Adjust and experiment with the number of parameters (10 points)\n",
    "\n",
    "- Step 4: Experiment with the depth and width of your neural network (10 points)\n",
    "\n",
    "- Step 5: Build an optimized neural network based on observations from previous tasks and analyze the performance (10 points).\n",
    "\n",
    "### Part 2: Convolutional neural network  ( 15 points)\n",
    "\n",
    "Use CNN to replace the vanilla neural network from Part 1 and report your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ftPSeJzHhenl"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "CYESQC1EjIyW",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "7d3d75a2-00b9-41b0-9c39-631622c61c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1455\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1075\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/data_utils.py:347\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/data_utils.py:85\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load CIFAR Dataset from Keras\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m (x_train_full, y_train_full), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mcifar10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Normalize pixel values to be between 0 and 1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x_train_full, x_test \u001b[38;5;241m=\u001b[39m x_train_full \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m, x_test \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/datasets/cifar10.py:81\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m dirname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar-10-batches-py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m origin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 81\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43muntar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m num_train_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m\n\u001b[1;32m     92\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((num_train_samples, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/data_utils.py:351\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39merrno, e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fpath):\n",
      "\u001b[0;31mException\u001b[0m: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)"
     ]
    }
   ],
   "source": [
    "# Load CIFAR Dataset from Keras\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert labels to binary class matrices\n",
    "num_classes = 10\n",
    "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Split the full training dataset into validation dataset in 80-20 ratio\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "collapsed": false,
    "id": "wvTS7alnjRGI",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cd7de172-5191-42ba-bb86-7c9a8665418d"
   },
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_images(X, y, number_of_images=10):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i in range(number_of_images):\n",
    "        plt.subplot(1, number_of_images, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_images(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX14lObF4pgt"
   },
   "source": [
    "## Part 1: Neural Network\n",
    "### Step 1: Build a simple neural network\n",
    "First, build a simple neural network for the CIFAR-10 dataset. You will need to:\n",
    "\n",
    "Load the CIFAR-10 dataset from Keras. Normalize the data and transform the labels to a categorical format.\n",
    "Define that simple neural network. This network should have at least **three** hidden layer using 'relu' activation and a softmax output layer for the 10 classes of the CIFAR-10 dataset.\n",
    "Compile the model. Use 'categorical_crossentropy' for your loss function and 'adam' as the optimizer. The metrics will be 'accuracy'.\n",
    "Train the model. Use a validation split of 0.2. Train for 10 epochs.\n",
    "Evaluate the model on the test set and report its accuracy.\n",
    "\n",
    "### Step 2: Change the activation\n",
    "Next, experiment with different activation functions. Repeat the Step 1 process three times-- once with 'relu' replaced with 'sigmoid', once with 'tanh', and finally with 'gelu'. For each, evaluate the model's performance and document any changes you observe.\n",
    "\n",
    "### Step 3: Change the number of parameters\n",
    "Now, significantly **increase** and **decrease** the number of parameters in your neural network (by an order of magnitude) and compare results. Observe and document how the number of network parameters influences the model's performance.\n",
    "\n",
    "### Step 4: Change the depth and width\n",
    "Now, experiment with the structure of your neural network, specifically its depth and width, and compare results while trying to keep the number of parameters fixed.\n",
    "\n",
    "***Increasing the depth***: Add more layers to your network. Try to make your model deeper by adding more layers of neurons. Keep note of how this affects training and performance.\n",
    "\n",
    "***Increasing the width***: Make your model wider by increasing the number of neurons in the hidden layers. Observe and document how this influences the model's performance.\n",
    "\n",
    "Remember that you are trying to keep the total number of parameters roughly equivalent for each alteration. This means that if you add more layers (increasing depth), you may need to reduce the number of neurons in each layer (decreasing width) to compensate, and vice versa. The aim is to explore the trade-off between network depth and width.\n",
    "\n",
    "Make sure to evaluate each alteration and compare it to the performance of your original network.\n",
    "\n",
    "### Step 5: Building an Optimized Neural Network\n",
    "Guided by your observations and findings from previous steps, it's now time to build an optimized neural network. Here are the tasks for this step:\n",
    "\n",
    "Design the Network: Based on your previous experiments, devise a network architecture that you believe will yield the best performance. Consider the number of layers, the number of neurons in each layer, and the activation functions.\n",
    "\n",
    "Compile the Model: Compile your model with the 'adam' optimizer and 'categorical_crossentropy' as the loss function. Use 'accuracy' as the evaluation metric as used previously.\n",
    "\n",
    "Train the Model: Train this model using the same parameters as the previous step (validation split of 0.2, 10 epochs). Remember to use the training data for training the model.\n",
    "\n",
    "Evaluate the Model: Evaluate your model on the test set and report the performance metrics.\n",
    "\n",
    "Analyze: Analyze if the designed model’s performance has improved as intended. Outline any strategies you used to improve the performance, and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1I9k_du7xDm"
   },
   "source": [
    "# Step 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urwvLZA44aYB"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "import keras\n",
    "\n",
    "# Load Data\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = 10\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "\n",
    "# Define Network\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "\n",
    "# Compile Model\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train Model\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "history = model.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g16-s8aG74eI"
   },
   "source": [
    "# Step 2:\n",
    "\n",
    "## Your findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boxe8Ce17_CP"
   },
   "outputs": [],
   "source": [
    "# Change activation function (sigmoid, tanh, gelu)\n",
    "activation_functions = ['sigmoid', 'tanh', 'gelu']\n",
    "\n",
    "for activation in activation_functions:\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(32, 32, 3)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWt1xCuE8fIP"
   },
   "source": [
    " # Step 3:\n",
    "\n",
    " ## Your findings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4KULS418tMk"
   },
   "outputs": [],
   "source": [
    "# increase number of parameters in the network\n",
    "model_increased = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(5120, activation='relu'),  \n",
    "    Dense(2560, activation='relu'),  \n",
    "    Dense(1280, activation='relu'),  \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# reduce number of parameters in the network\n",
    "model_reduced = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(320, activation='relu'),  \n",
    "    Dense(160, activation='relu'), \n",
    "    Dense(80, activation='relu'),  \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# summary\n",
    "model_increased.summary()\n",
    "model_reduced.summary()\n",
    "\n",
    "# Compile the Model\n",
    "model_increased.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_reduced.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history_increased = model_high_params.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "history_reduced = model_low_params.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss_inc, test_acc_inc = model_increased.evaluate(x_test, y_test)\n",
    "test_loss_red, test_acc_red = model_reduced.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikiG8r2w867A"
   },
   "source": [
    "# Step 4:\n",
    "\n",
    " ## Your findings and report the number of parameters as well (should be the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SI7IiwR38_Ie"
   },
   "outputs": [],
   "source": [
    "# Increase width, decrease depth\n",
    "model_W = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(512, activation='relu'),  \n",
    "    Dense(256, activation='relu'),  \n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Increase depth, decrease width\n",
    "model_D = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(256, activation='relu'), \n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(64, activation='relu'),  \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model_W.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_D.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "model_W.summary()\n",
    "model_D.summary()\n",
    "\n",
    "# Train the Model\n",
    "history_W = model_W.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "history_D = model_D.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "test_loss_W, test_acc_W = model_W.evaluate(x_test, y_test)\n",
    "test_loss_D, test_acc_D = model_D.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99uzMJfH-TBT"
   },
   "source": [
    "# Step 5: Building an Optimized Neural Network\n",
    "\n",
    "\n",
    "## Discsuss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwcJ10tx-Rth"
   },
   "outputs": [],
   "source": [
    "# Your network here\n",
    "model_optimized = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model_optimized.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "model_optimized.summary()\n",
    "\n",
    "# Train the Model\n",
    "history_optimized = model_optimized.fit(x_train_full, y_train_full, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss_optimized, test_acc_optimized = model_optimized.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 CNN\n",
    "\n",
    "Utilizing the Keras Sequential model, define a Convolutional Neural Network (CNN) model that is adapted to classify images in the CIFAR-10 dataset. Add the necessary layers to the model.\n",
    "\n",
    "For example: * Convolutional layer * Pooling layer * Dropout layer * Flatten layer * Fully connected layer. Of course, you can use whatever you want.\n",
    "\n",
    "Make sure to select appropriate activation functions for the layers. Share your findings about CNN for image classification compared to the neural network of Part 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# Load Data\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
    "\n",
    "# Model definition\n",
    "model =\n",
    "\n",
    "\n",
    "# compile the model\n",
    "\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
